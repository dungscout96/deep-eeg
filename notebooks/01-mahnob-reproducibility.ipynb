{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f47416d-8ada-44ee-92be-9491bfecb748",
   "metadata": {},
   "source": [
    "# Mahnob Baseline\n",
    "\n",
    "Using leave one subject out, evaluate EEG-only spectral power and vgg topo features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07527a46-0e18-4c77-a992-2f97b6153910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1915a5d0-d430-4749-b328-6efe6100258d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/masaponto/python-elm\n",
      "  Cloning https://github.com/masaponto/python-elm to /tmp/pip-req-build-z7jky97w\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/masaponto/python-elm /tmp/pip-req-build-z7jky97w\n",
      "  Resolved https://github.com/masaponto/python-elm to commit b253b5c262efeb1f8eeb5e14b55f98778409b54d\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.18.1 in /opt/conda/lib/python3.10/site-packages (from elm==0.4.1) (1.1.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from elm==0.4.1) (1.23.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.18.1->elm==0.4.1) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.18.1->elm==0.4.1) (1.9.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.18.1->elm==0.4.1) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/masaponto/python-elm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9a35146-7e90-4e6b-a516-12798715817e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-753n1gzq because the default path (/home/anp054/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from libs.dataloaders import mahnob\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from elm import ELM\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "863a6d45-aaee-41d1-8775-80fe447fe020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sessions_subjs():\n",
    "    path = \"/net2/expData/affective_eeg/mahnob_dataset/Sessions\"\n",
    "    sessions = os.listdir(path)\n",
    "    subjs = {}\n",
    "    scores = {}\n",
    "    for session in sessions:\n",
    "        mytree = ET.parse(f'{path}/{session}/session.xml')\n",
    "        myroot = mytree.getroot()\n",
    "        if myroot[0].attrib['id'] not in subjs:\n",
    "            subjs[myroot[0].attrib['id']] = []\n",
    "        if 'feltVlnc' in myroot.attrib:\n",
    "            subjs[myroot[0].attrib['id']].append(session)\n",
    "            scores[session] = int(myroot.attrib['feltVlnc'])\n",
    "    return subjs, scores\n",
    "subjects, subject_scores = get_sessions_subjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c6f4e3d-ee6a-4bff-8e70-22439322175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subject_cv(dataset_vgg, subjects):\n",
    "    \"\"\"\n",
    "    Run per subject cross-validation using ELM (sweeping neuron size 1-200) and LDA.\n",
    "    Notes:\n",
    "        - Do _not_ enforce balancing on training, but set equal priors for LDA (data is roughly balanced)\n",
    "        - Balance test data; skip when per-label count < 3\n",
    "        - When sweeping ELM neurons, fix the error in the original paper implementation where they\n",
    "          are fitting to test accuracy. Instead tune on training, and then evaluate on test.\n",
    "    \"\"\"\n",
    "    lda_acc, elm_acc = [], []\n",
    "    for sessions in tqdm(subjects.values()):\n",
    "        train_data = [dataset_vgg[i] for i in range(len(dataset_vgg)) if dataset_vgg.sessions[i] not in sessions]\n",
    "        test_data = [dataset_vgg[i] for i in range(len(dataset_vgg)) if dataset_vgg.sessions[i] in sessions]\n",
    "        \n",
    "        X_train_vgg = np.array([i[0].flatten() for i in train_data])\n",
    "        Y_train_vgg = np.squeeze([i[1] for i in train_data])*2-1 # rescale to -1, 1\n",
    "        X_test_vgg = np.array([i[0].flatten() for i in test_data])\n",
    "        Y_test_vgg = np.squeeze([i[1] for i in test_data])*2-1 # rescale to -1, 1\n",
    "\n",
    "        if len(Y_train_vgg) == 0 or len(Y_test_vgg) == 0:\n",
    "            continue\n",
    "        if len(np.unique(Y_test_vgg, return_counts=True)[-1]) != len(np.unique(Y_train_vgg, return_counts=True)[-1]):\n",
    "            print(\"Skipping due to num classes not being equivalent in train and test\")\n",
    "            continue\n",
    "        \n",
    "        # This really only works for 2 classes; balance\n",
    "        u_val, u_count = np.unique(Y_test_vgg, return_counts=True)\n",
    "        u_count = list(u_count)\n",
    "        if u_count[0] != u_count[1]:\n",
    "            u_reduce = u_val[u_count.index(max(u_count))]\n",
    "            u_reduce_count = abs(u_count[0] - u_count[1])\n",
    "            match_idxs = np.argwhere(Y_test_vgg == u_reduce).squeeze()\n",
    "            np.random.shuffle(match_idxs)\n",
    "            remove_idxs = match_idxs[:u_reduce_count]\n",
    "            keep_idxs = [i for i in range(len(Y_test_vgg)) if i not in remove_idxs]\n",
    "            X_test_vgg = X_test_vgg[keep_idxs]\n",
    "            Y_test_vgg = Y_test_vgg[keep_idxs]\n",
    "        \n",
    "        if min(np.unique(Y_test_vgg, return_counts=True)[-1]) < 3:\n",
    "            print(\"Skipping due to fewer than 3 samples per class\")\n",
    "            continue\n",
    "\n",
    "        # Shuffle train\n",
    "        shuffle = np.arange(X_train_vgg.shape[0])\n",
    "        np.random.shuffle(shuffle)\n",
    "        X_train_vgg = X_train_vgg[shuffle]\n",
    "        Y_train_vgg = Y_train_vgg[shuffle]\n",
    "\n",
    "        pca = PCA(n_components=30)\n",
    "        pca.fit(X_train_vgg)\n",
    "        X_train_vgg = pca.transform(X_train_vgg)\n",
    "        X_test_vgg = pca.transform(X_test_vgg)\n",
    "\n",
    "        lda = LinearDiscriminantAnalysis(priors=(0.5,0.5))\n",
    "        lda.fit(X_train_vgg, Y_train_vgg)\n",
    "        lda_test = lda.score(X_test_vgg, Y_test_vgg)\n",
    "\n",
    "        best_q = (0, 0) # neuron, train_perf\n",
    "        for q in range(1,200):\n",
    "            elm = ELM(hid_num=q).fit(X_train_vgg, Y_train_vgg)\n",
    "            score = elm.score(X_train_vgg, Y_train_vgg)\n",
    "            if score > best_q[1]:\n",
    "                best_q = (q, score)\n",
    "        elm = ELM(hid_num=best_q[0]).fit(X_train_vgg, Y_train_vgg)\n",
    "        elm_test = elm.score(X_test_vgg, Y_test_vgg)\n",
    "            \n",
    "        lda_acc.append(lda_test)\n",
    "        elm_acc.append(elm_test)\n",
    "        # print(lda_test, elm_test)\n",
    "\n",
    "    print(f\"LDA: {np.mean(lda_acc):.2f} +/- {np.std(lda_acc)/np.sqrt(len(lda_acc)):.3f}\")\n",
    "    print(f\"ELM: {np.mean(elm_acc):.2f} +/- {np.std(elm_acc)/np.sqrt(len(elm_acc)):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6ee7aad-7c0c-4b17-90a3-c86f9d097b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def vgg16_augment(model):\n",
    "    model.classifier = torch.nn.Sequential(*list(model.classifier.children())[:-3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe8d997-89b9-4d55-aec5-f16434c04faf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Average Spectral Power\n",
    "\n",
    "Average Theta, Alpha, Beta, Gamma features per channel. The performance results are reported as LDA and ELM (note: this ELM version uses the max neuron count performance value _per subject_ that Sid's paper used)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe0be7b5-0580-4d88-9c7f-a0d838455d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 526/526 [00:11<00:00, 45.81it/s]\n",
      "100%|██████████| 526/526 [00:34<00:00, 15.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: T dimension is not equivalent across all S; reducing to T=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = mahnob.MahnobDataset(\n",
    "    x_params={\n",
    "        \"feature\": \"AvgFreqPower\", \n",
    "        \"window\": -1,\n",
    "        \"stride\": -1\n",
    "    },\n",
    "    sessions=None,\n",
    "    y_mode='bimodal',\n",
    "    y_keys=['feltVlnc'],\n",
    "    seed=49\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "106907b1-5ce4-47fe-be5f-927c16984f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4/29 [00:10<01:04,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 8/29 [00:15<00:36,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to num classes not being equivalent in train and test\n",
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 22/29 [00:43<00:17,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:59<00:00,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: 0.59 +/- 0.024\n",
      "ELM: 0.54 +/- 0.037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "subject_cv(dataset, subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e837097d-851b-48ed-8de4-53efd1517234",
   "metadata": {
    "tags": []
   },
   "source": [
    "## VGG Topo Features\n",
    "\n",
    "Average Theta, Alpha, Beta topo fed through pretrained VGG16 model. The performance results are reported as LDA and ELM (note: this ELM version uses the max neuron count performance value _per subject_ that Sid's paper used)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2cc9192-6670-4512-a0ff-d52e94e46c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 526/526 [00:10<00:00, 51.31it/s]\n",
      "100%|██████████| 526/526 [02:25<00:00,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: T dimension is not equivalent across all S; reducing to T=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = mahnob.MahnobDataset(\n",
    "    x_params={\n",
    "        \"feature\": \"TopomapNN\",\n",
    "        \"model\": \"vgg16\",\n",
    "        \"model_params\": {\n",
    "            \"weights\": \"DEFAULT\",\n",
    "        },\n",
    "        \"model_augment_fn\": vgg16_augment,\n",
    "        \"window\": -1,\n",
    "        \"stride\": -1\n",
    "    },\n",
    "    sessions=None,\n",
    "    y_mode='bimodal',\n",
    "    y_keys=['feltVlnc'],\n",
    "    seed=49\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d31d968e-4bb1-4596-ae14-8e0cdc50ba31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4/29 [00:10<01:06,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 8/29 [00:16<00:38,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to num classes not being equivalent in train and test\n",
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 22/29 [00:45<00:18,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [01:01<00:00,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: 0.52 +/- 0.018\n",
      "ELM: 0.51 +/- 0.033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "subject_cv(dataset, subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e36a048-82f3-458a-bcdc-64880bae1620",
   "metadata": {},
   "source": [
    "# Window Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da2cd7e-63b6-4bfb-aa65-45d6a8e9db1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Average Spectral Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5030cb78-79cb-4170-9ff8-d3afb65ae852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 526/526 [00:07<00:00, 70.45it/s]\n",
      "100%|██████████| 526/526 [00:35<00:00, 14.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: T dimension is not equivalent across all S; reducing to T=9\n"
     ]
    }
   ],
   "source": [
    "dataset = mahnob.MahnobDataset(\n",
    "    x_params={\n",
    "        \"feature\": \"AvgFreqPower\", \n",
    "        \"window\": 2560, # 10s window\n",
    "        \"stride\": 2560, # 10s stride\n",
    "    },\n",
    "    sessions=None,\n",
    "    y_mode='bimodal',\n",
    "    y_keys=['feltVlnc'],\n",
    "    seed=49\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f72f09e-f9fc-425e-b410-bbaffdbc4303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4/29 [00:10<01:06,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 8/29 [00:15<00:38,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to num classes not being equivalent in train and test\n",
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 22/29 [00:44<00:17,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [01:00<00:00,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: 0.61 +/- 0.026\n",
      "ELM: 0.54 +/- 0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "subject_cv(dataset, subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6583e8e5-1eaf-41db-85d8-eede5acffc17",
   "metadata": {
    "tags": []
   },
   "source": [
    "## VGG Topo Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6003454b-826e-4156-985c-7f81056ee48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 526/526 [00:06<00:00, 78.50it/s]\n",
      "100%|██████████| 526/526 [25:07<00:00,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: T dimension is not equivalent across all S; reducing to T=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = mahnob.MahnobDataset(\n",
    "    x_params={\n",
    "        \"feature\": \"TopomapNN\",\n",
    "        \"model\": \"vgg16\",\n",
    "        \"model_params\": {\n",
    "            \"weights\": \"DEFAULT\",\n",
    "        },\n",
    "        \"model_augment_fn\": vgg16_augment,\n",
    "        \"window\": 2560, # 10s window\n",
    "        \"stride\": 2560, # 10s stride\n",
    "    },\n",
    "    sessions=None,\n",
    "    y_mode='bimodal',\n",
    "    y_keys=['feltVlnc'],\n",
    "    seed=49\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93b94487-7109-4189-aa29-59326313066f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4/29 [00:12<01:17,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 8/29 [00:18<00:44,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to num classes not being equivalent in train and test\n",
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 22/29 [00:53<00:21,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [01:12<00:00,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: 0.57 +/- 0.020\n",
      "ELM: 0.55 +/- 0.031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "subject_cv(dataset, subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feb55ea-d9e7-47b7-9383-61020e01ab7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Random Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3058e17-4fa7-407b-bc3d-2eb6bad7a454",
   "metadata": {},
   "source": [
    "## Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8098870-cfbe-4971-8e1e-bf11620597d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 526/526 [04:46<00:00,  1.84it/s]\n",
      "100%|██████████| 526/526 [02:19<00:00,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: T dimension is not equivalent across all S; reducing to T=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = mahnob.MahnobDataset(\n",
    "    x_params={\n",
    "        \"feature\": \"TopomapNN\",\n",
    "        \"model\": \"vgg16\",\n",
    "        \"model_params\": {\n",
    "            \"weights\": \"DEFAULT\",\n",
    "        },\n",
    "        \"model_augment_fn\": vgg16_augment,\n",
    "        \"window\": -1,\n",
    "        \"stride\": -1\n",
    "    },\n",
    "    sessions=None,\n",
    "    y_mode='bimodal',\n",
    "    y_keys=['feltVlnc'],\n",
    "    seed=49\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c38c1e34-045c-4f44-991f-35cef15595a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4/29 [00:10<01:06,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 8/29 [00:16<00:38,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to num classes not being equivalent in train and test\n",
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 22/29 [00:45<00:18,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [01:01<00:00,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: 0.53 +/- 0.017\n",
      "ELM: 0.46 +/- 0.039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "subject_cv(dataset, subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73149369-6ec5-4a3c-b445-50131dfb0886",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = []\n",
    "for param in dataset.x_transformer.model.parameters():\n",
    "    default_params.append(param.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8aedef-a296-4842-a119-f196b2893d5e",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30236a15-8769-45df-982c-4c6fb0728757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 526/526 [02:52<00:00,  3.05it/s]\n",
      "100%|██████████| 526/526 [02:17<00:00,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: T dimension is not equivalent across all S; reducing to T=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = mahnob.MahnobDataset(\n",
    "    x_params={\n",
    "        \"feature\": \"TopomapNN\",\n",
    "        \"model\": \"vgg16\",\n",
    "        \"model_params\": {\n",
    "            \"weights\": \"DEFAULT\",\n",
    "        },\n",
    "        \"model_augment_fn\": vgg16_augment,\n",
    "        \"random_weights\": {\n",
    "            \"mode\": \"rand_init\"\n",
    "        },\n",
    "        \"window\": -1,\n",
    "        \"stride\": -1\n",
    "    },\n",
    "    sessions=None,\n",
    "    y_mode='bimodal',\n",
    "    y_keys=['feltVlnc'],\n",
    "    seed=49\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3359057-a432-43c6-ac56-6e17b0b6aa31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4/29 [00:10<01:04,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 8/29 [00:15<00:36,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to num classes not being equivalent in train and test\n",
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 22/29 [00:43<00:17,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:59<00:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: 0.54 +/- 0.024\n",
      "ELM: 0.54 +/- 0.042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "subject_cv(dataset, subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "657515d3-6ec3-43f4-9182-079796cb56e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params = []\n",
    "for param in dataset.x_transformer.model.parameters():\n",
    "    init_params.append(param.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcd17a3-4ec1-4725-954e-0c7ce6bdd7fd",
   "metadata": {},
   "source": [
    "## Perturb Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85be5193-8e05-45b4-9747-d9e29acbc5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 526/526 [03:10<00:00,  2.76it/s]\n",
      "100%|██████████| 526/526 [02:18<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: T dimension is not equivalent across all S; reducing to T=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = mahnob.MahnobDataset(\n",
    "    x_params={\n",
    "        \"feature\": \"TopomapNN\",\n",
    "        \"model\": \"vgg16\",\n",
    "        \"model_params\": {\n",
    "            \"weights\": \"DEFAULT\",\n",
    "        },\n",
    "        \"model_augment_fn\": vgg16_augment,\n",
    "        \"random_weights\": {\n",
    "            \"mode\": \"perturb\",\n",
    "            \"distribution\": \"uniform\",\n",
    "        },\n",
    "        \"window\": -1,\n",
    "        \"stride\": -1\n",
    "    },\n",
    "    sessions=None,\n",
    "    y_mode='bimodal',\n",
    "    y_keys=['feltVlnc'],\n",
    "    seed=49\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9dd14ca8-9231-4d39-8a11-078845e170d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4/29 [00:09<01:02,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 8/29 [00:14<00:35,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to num classes not being equivalent in train and test\n",
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 22/29 [00:42<00:16,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:57<00:00,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: 0.48 +/- 0.025\n",
      "ELM: 0.49 +/- 0.033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "subject_cv(dataset, subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a91b722-12a0-44a7-8c20-ddef91fd6f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturb_params = []\n",
    "for param in dataset.x_transformer.model.parameters():\n",
    "    perturb_params.append(param.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b832606d-093d-4726-a0d1-73cdd8314791",
   "metadata": {},
   "source": [
    "## Shuffle Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "957dcdb7-7a16-4615-a68e-7f2a561e7f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 526/526 [03:03<00:00,  2.86it/s]\n",
      "100%|██████████| 526/526 [03:20<00:00,  2.62it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: T dimension is not equivalent across all S; reducing to T=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = mahnob.MahnobDataset(\n",
    "    x_params={\n",
    "        \"feature\": \"TopomapNN\",\n",
    "        \"model\": \"vgg16\",\n",
    "        \"model_params\": {\n",
    "            \"weights\": \"DEFAULT\",\n",
    "        },\n",
    "        \"model_augment_fn\": vgg16_augment,\n",
    "        \"random_weights\": {\n",
    "            \"mode\": \"shuffle\"\n",
    "        },\n",
    "        \"window\": -1,\n",
    "        \"stride\": -1\n",
    "    },\n",
    "    sessions=None,\n",
    "    y_mode='bimodal',\n",
    "    y_keys=['feltVlnc'],\n",
    "    seed=49\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5c25ed4-228a-4fb1-ac01-b2e18a5bc3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4/29 [00:12<01:16,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 8/29 [00:18<00:43,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to num classes not being equivalent in train and test\n",
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 22/29 [00:51<00:20,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [01:09<00:00,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: 0.52 +/- 0.020\n",
      "ELM: 0.49 +/- 0.033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "subject_cv(dataset, subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a08e24e9-c35c-4444-881c-dc7e2ff77d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_params = []\n",
    "for param in dataset.x_transformer.model.parameters():\n",
    "    shuffled_params.append(param.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97ad248-1645-448c-b5a6-af459089aa27",
   "metadata": {},
   "source": [
    "## Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1b02875-712e-4568-91ce-452fc324405c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4034,  0.3778,  0.4644, -0.3228,  0.3940, -0.3953,  0.3951, -0.5496,\n",
       "         0.2693, -0.7602, -0.3508,  0.2334, -1.3239, -0.1694,  0.3938, -0.1026,\n",
       "         0.0460, -0.6995,  0.1549,  0.5628,  0.3011,  0.3425,  0.1073,  0.4651,\n",
       "         0.1295,  0.0788, -0.0492, -0.5638,  0.1465, -0.3890, -0.0715,  0.0649,\n",
       "         0.2768,  0.3279,  0.5682, -1.2640, -0.8368, -0.9485,  0.1358,  0.2727,\n",
       "         0.1841, -0.5325,  0.3507, -0.0827, -1.0248, -0.6912, -0.7711,  0.2612,\n",
       "         0.4033, -0.4802, -0.3066,  0.5807, -1.3325,  0.4844, -0.8160,  0.2386,\n",
       "         0.2300,  0.4979,  0.5553,  0.5230, -0.2182,  0.0117, -0.5516,  0.2108],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "798d1e1c-feb8-4a59-a8b5-e76992617ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0168,  0.1491, -0.1472,  0.0163, -0.0874,  0.0912, -0.1743,  0.0006,\n",
       "         0.0752,  0.1656, -0.1164, -0.1686, -0.0331,  0.1895,  0.0928, -0.0934,\n",
       "         0.1055,  0.0024,  0.1031, -0.1847,  0.1808, -0.1919, -0.0429,  0.0382,\n",
       "         0.1669,  0.1425,  0.0551,  0.0876,  0.0966, -0.0807,  0.1244, -0.1771,\n",
       "         0.0930,  0.1858, -0.0774,  0.1246, -0.0735, -0.0906,  0.0064, -0.0687,\n",
       "         0.0907, -0.1748,  0.0366, -0.0847,  0.0744, -0.1750,  0.1017, -0.1890,\n",
       "         0.1362, -0.0869, -0.0358,  0.0219,  0.0804, -0.0770, -0.0837,  0.1533,\n",
       "         0.1290, -0.0759,  0.0127, -0.0010, -0.0464, -0.1196, -0.1643,  0.0142],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d541e1b1-894d-4df6-8978-d8d0566e795f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4161,  0.3915,  0.4802, -0.3114,  0.4050, -0.3841,  0.4140, -0.5352,\n",
       "         0.2805, -0.7452, -0.3358,  0.2523, -1.3126, -0.1548,  0.4053, -0.0873,\n",
       "         0.0604, -0.6823,  0.1692,  0.5766,  0.3110,  0.3587,  0.1178,  0.4829,\n",
       "         0.1464,  0.0955, -0.0379, -0.5503,  0.1631, -0.3703, -0.0585,  0.0817,\n",
       "         0.2877,  0.3382,  0.5810, -1.2497, -0.8190, -0.9364,  0.1474,  0.2857,\n",
       "         0.1946, -0.5137,  0.3650, -0.0650, -1.0104, -0.6750, -0.7520,  0.2712,\n",
       "         0.4177, -0.4675, -0.2898,  0.5982, -1.3196,  0.4987, -0.8042,  0.2532,\n",
       "         0.2447,  0.5163,  0.5682,  0.5365, -0.2059,  0.0226, -0.5352,  0.2283],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturb_params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f65c837d-889a-4bb9-a936-5ad0de7d98ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3425,  0.3778, -0.5496,  0.0788,  0.2727,  0.2693,  0.2386,  0.5628,\n",
       "         0.1295,  0.1841, -1.2640,  0.5230,  0.5682,  0.3011,  0.0649, -1.3239,\n",
       "         0.3938,  0.1465,  0.2768, -0.3508,  0.4033, -1.3325,  0.2300,  0.0117,\n",
       "        -0.9485, -0.1026,  0.2334,  0.5553,  0.4844,  0.0460, -0.8160, -0.0492,\n",
       "        -0.2182, -0.0827,  0.1358, -0.5325,  0.4644, -0.5638, -0.6995,  0.4651,\n",
       "        -0.6912, -0.4802,  0.4034, -0.8368,  0.3507, -0.3066,  0.3951, -0.3953,\n",
       "        -0.3228, -1.0248,  0.1549,  0.5807, -0.5516, -0.1694, -0.7602, -0.7711,\n",
       "         0.3279, -0.0715,  0.3940,  0.2612,  0.1073, -0.3890,  0.4979,  0.2108],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_params[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f379b85-1850-4428-b21e-e0ba5e56d0ac",
   "metadata": {},
   "source": [
    "# Alt Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "072c101d-de05-4a5f-96e9-2b3024a75d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 526/526 [03:08<00:00,  2.79it/s]\n",
      "100%|██████████| 526/526 [01:27<00:00,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: T dimension is not equivalent across all S; reducing to T=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = mahnob.MahnobDataset(\n",
    "    x_params={\n",
    "        \"feature\": \"TopomapNN\",\n",
    "        \"model\": \"alexnet\",\n",
    "        \"model_params\": {\n",
    "            \"weights\": \"DEFAULT\",\n",
    "        },\n",
    "        \"model_augment_fn\": vgg16_augment, # using same transform for alexnet\n",
    "        \"window\": -1,\n",
    "        \"stride\": -1\n",
    "    },\n",
    "    sessions=None,\n",
    "    y_mode='bimodal',\n",
    "    y_keys=['feltVlnc'],\n",
    "    seed=49\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "173b93f7-2fef-4a44-83c2-408065374e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4/29 [00:11<01:10,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 8/29 [00:17<00:40,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to num classes not being equivalent in train and test\n",
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 22/29 [00:48<00:19,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [01:05<00:00,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: 0.55 +/- 0.025\n",
      "ELM: 0.56 +/- 0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "subject_cv(dataset, subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cbab42ec-ca8d-4a74-bb38-715424da7594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 526/526 [01:57<00:00,  4.46it/s]\n",
      "100%|██████████| 526/526 [03:11<00:00,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: T dimension is not equivalent across all S; reducing to T=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = mahnob.MahnobDataset(\n",
    "    x_params={\n",
    "        \"feature\": \"TopomapNN\",\n",
    "        \"model\": \"efficientnet_v2_l\",\n",
    "        \"model_params\": {\n",
    "            \"weights\": \"DEFAULT\",\n",
    "        },\n",
    "        \"model_augment_fn\": vgg16_augment, # using same transform for efficientnet\n",
    "        \"window\": -1,\n",
    "        \"stride\": -1\n",
    "    },\n",
    "    sessions=None,\n",
    "    y_mode='bimodal',\n",
    "    y_keys=['feltVlnc'],\n",
    "    seed=49\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d475689a-f957-4169-bddd-29e27d099197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4/29 [00:11<01:08,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 8/29 [00:16<00:39,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to num classes not being equivalent in train and test\n",
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 22/29 [00:47<00:18,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to fewer than 3 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [01:03<00:00,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: 0.52 +/- 0.029\n",
      "ELM: 0.58 +/- 0.024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "subject_cv(dataset, subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf199c4-3ad0-4265-81ce-aea183ffd804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
