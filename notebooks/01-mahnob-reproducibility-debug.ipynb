{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554b3139-1b37-49ad-b92b-c75c0ac292ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This has our asr preprocessing, but sid's psd feature transform\n",
    "basedir = '/net2/derData/affective_eeg/eeg/asr_pwr_feats_sid'\n",
    "import scipy\n",
    "import os\n",
    "mat_feats = {}\n",
    "for f in os.listdir(basedir):\n",
    "    mat = scipy.io.loadmat(os.path.join(basedir, f))\n",
    "    \n",
    "    mat_feats[f.split(\"_\")[0]] = {\n",
    "        \"features\": mat['data'][0],\n",
    "        \"ch_names\": [i[0].strip() for i in mat['ch_names'][0]]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4b2422-2d0b-40b8-aba9-ba626a0afd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad832680-7edf-4ffe-9763-2c6c4d34bbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.interpolate\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def topo(data):\n",
    "\n",
    "    def fig2data ( fig ):\n",
    "        # draw the renderer\n",
    "        fig.canvas.draw()\n",
    "\n",
    "        # Get the RGBA buffer from the figure\n",
    "        w,h = fig.canvas.get_width_height()\n",
    "        buf = np.fromstring(fig.canvas.tostring_argb(), dtype=np.uint8)\n",
    "        buf.shape = ( w, h, 4)\n",
    "\n",
    "        # canvas.tostring_argb give pixmap in ARGB mode. Roll the ALPHA channel to have it in RGBA mode\n",
    "        buf = np.roll ( buf, 3, axis = 2 )\n",
    "        return buf\n",
    "\n",
    "    def fig2img ( fig ):\n",
    "        # put the figure pixmap into a numpy array\n",
    "        buf = fig2data(fig)\n",
    "        w, h, d = buf.shape\n",
    "        return Image.frombytes( \"RGBA\", ( w ,h ), buf.tostring( ) )\n",
    "\n",
    "    EEG_PSD = np.array(data['features'])\n",
    "    # print EEG_PSD.shape\n",
    "\n",
    "    # sensor_names = ['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2','P8', 'T8', 'FC6', 'F4', 'F8', 'AF4']\n",
    "    # koord = [[1,4],[0,3],[1,3],[0.5,2.5],[0,2],[0,1],[1,0],[3,0],[4,1],[4,2],[3.5,2.5],[3,3],[4,3],[3,4]] \n",
    "    sensor_names = ['Fp1','AF3','F3','F7','FC5','FC1','C3','T7','CP5','CP1','P3','P7','PO3','O1','Oz','Pz','Fp2','AF4','Fz','F4','F8','FC6','FC2','Cz','C4','T8','CP6','CP2','P4','P8','PO4','O2']\n",
    "    koord = [[1,4],[1,3.5],[1,3],[0.25,3],[0.5,2.5],[1.5,2.5],[1,2],[0,2],[0.5,1.5],[1.5,1.5],[1,1],[0.25,1],[1,0.5],[1,0],[2,0],[2,1],[3,4],[3,3.5],[2,3],[3,3],[3.75,3],[3.5,2.5],[2.5,2.5],[2,2],[3,2],[4,2],[3.5,1.5],[2.5,1.5],[3,1],[3.75,1],[3,0.5],[3,0]] \n",
    "    N_points = 200\n",
    "    xy_center = (2,2)\n",
    "    radius = 2\n",
    "\n",
    "    x, y = [], []\n",
    "\n",
    "    for i in koord:\n",
    "        x.append(i[0])\n",
    "        y.append(i[1])\n",
    "\n",
    "    xi = np.linspace(-2,6,N_points)\n",
    "    yi = np.linspace(-2,6,N_points)\n",
    "\n",
    "    # For theta, alpha and beta bands\n",
    "    fig_t = plt.figure()\n",
    "    plt.close()\n",
    "    fig_a = plt.figure()\n",
    "    plt.close()\n",
    "    fig_b = plt.figure()\n",
    "    plt.close()\n",
    "\n",
    "    ax_t = fig_t.add_subplot(111, aspect = 1)\n",
    "    ax_a = fig_a.add_subplot(111, aspect = 1)\n",
    "    ax_b = fig_b.add_subplot(111, aspect = 1)\n",
    "    # ax_t.scatter(x, y, marker = 'o', c = 'b', s = 15, zorder = 3)\n",
    "\n",
    "    # remove the ticks\n",
    "    ax_t.set_xticks([])\n",
    "    ax_t.set_yticks([])\n",
    "    ax_a.set_xticks([])\n",
    "    ax_a.set_yticks([])\n",
    "    ax_b.set_xticks([])\n",
    "    ax_b.set_yticks([])\n",
    "\n",
    "    ax_t.set_xlim(0, 4)\n",
    "    ax_t.set_ylim(0, 4)\n",
    "    ax_a.set_xlim(0, 4)\n",
    "    ax_a.set_ylim(0, 4)\n",
    "    ax_b.set_xlim(0, 4)\n",
    "    ax_b.set_ylim(0, 4)\n",
    "\n",
    "    max_val = np.array([0.0,0.0,0.0])\n",
    "\n",
    "\n",
    "    # For theta, alpha and beta bands\n",
    "    zi_t = scipy.interpolate.griddata((x, y), EEG_PSD[0:32], (xi[None,:], yi[:,None]), method = 'cubic')\n",
    "    zi_a = scipy.interpolate.griddata((x, y), EEG_PSD[32:64], (xi[None,:], yi[:,None]), method = 'cubic')\n",
    "    zi_b = scipy.interpolate.griddata((x, y), EEG_PSD[64:96], (xi[None,:], yi[:,None]), method = 'cubic')\n",
    "\n",
    "    max_val[0] = np.nanmax(zi_t)\n",
    "    max_val[1] = np.nanmax(zi_a)\n",
    "    max_val[2] = np.nanmax(zi_b)\n",
    "\n",
    "    max_ind = np.argmax(max_val)\n",
    "    max_val_scaled = max_val / max_val[max_ind]\n",
    "    # print max_val_scaled\n",
    "\n",
    "    CS_t = ax_t.contourf(xi, yi, zi_t, 60, cmap = plt.cm.Reds, zorder = 1)\n",
    "    CS_a = ax_a.contourf(xi, yi, zi_a, 60, cmap = plt.cm.Greens, zorder = 1)\n",
    "    CS_b = ax_b.contourf(xi, yi, zi_b, 60, cmap = plt.cm.Blues, zorder = 1)\n",
    "\n",
    "    im_t = fig2img(fig_t)\n",
    "    im_a = fig2img(fig_a)\n",
    "    im_b = fig2img(fig_b)\n",
    "\n",
    "    im_np_t = np.array(im_t)\n",
    "    im_np_t = np.rot90(im_np_t, 1)\n",
    "    im_np_t = im_np_t[::-1]\n",
    "    im_np_t = im_np_t[136:520, 48:432, :]\n",
    "\n",
    "    im_np_a = np.array(im_a)\n",
    "    im_np_a = np.rot90(im_np_a, 1)\n",
    "    im_np_a = im_np_a[::-1]\n",
    "    im_np_a = im_np_a[136:520, 48:432, :]\n",
    "\n",
    "    im_np_b = np.array(im_b)\n",
    "    im_np_b = np.rot90(im_np_b, 1)\n",
    "    im_np_b = im_np_b[::-1]\n",
    "    im_np_b = im_np_b[136:520, 48:432, :]\n",
    "\n",
    "    added_img = im_np_t + im_np_a + im_np_b\n",
    "    return added_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824a031f-1aaa-48c2-bd11-0ceac47a419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_maps = {k: topo(v) for k,v in mat_feats.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4400cbe-71c2-44ef-a687-f45a9e835709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sessions_subjs():\n",
    "    path = \"/net2/expData/affective_eeg/mahnob_dataset/Sessions\"\n",
    "    sessions = os.listdir(path)\n",
    "    subjs = {}\n",
    "    scores = {}\n",
    "    for session in sessions:\n",
    "        mytree = ET.parse(f'{path}/{session}/session.xml')\n",
    "        myroot = mytree.getroot()\n",
    "        if myroot[0].attrib['id'] not in subjs:\n",
    "            subjs[myroot[0].attrib['id']] = []\n",
    "        if 'feltVlnc' in myroot.attrib:\n",
    "            subjs[myroot[0].attrib['id']].append(session)\n",
    "            scores[session] = int(myroot.attrib['feltVlnc'])\n",
    "    return subjs, scores\n",
    "subjects, subject_scores = get_sessions_subjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e30a31c-846a-4e38-b033-56625cacaf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat by subject\n",
    "subject_data = []\n",
    "valid_sessions = []\n",
    "for subject, sessions in subjects.items():\n",
    "    sessions_used = [session for session in sessions if session in head_maps]\n",
    "    combined_data = np.array([head_maps[session] for session in sessions_used])\n",
    "    if len(combined_data) > 0:\n",
    "        subject_data.append(combined_data)\n",
    "        valid_sessions.append(sessions_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab385ee-1d28-4a47-a058-59b69f3db0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = np.concatenate(subject_data)[:,:,:,:3]\n",
    "all_data = np.transpose(all_data, (0,3,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ef2e44-da3a-475e-9d55-e711cc842b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import vgg16\n",
    "model = vgg16(weights='DEFAULT')\n",
    "model.classifier = torch.nn.Sequential(*list(model.classifier.children())[:-3])\n",
    "model.eval()\n",
    "if torch.cuda.is_available():\n",
    "    model.to('cuda')\n",
    "\n",
    "all_vgg_feats = []\n",
    "for i in range(31): # HACK: len(all_data) / 31\n",
    "    feat_tensor = torch.tensor(all_data[31*i:(i+1)*31], dtype=torch.float, device=\"cuda\" if torch.cuda.is_available() else \"cpu\") # S T F\n",
    "    with torch.no_grad():\n",
    "        result = model(feat_tensor)\n",
    "    del feat_tensor # free gpu memory\n",
    "\n",
    "    result = result.numpy(force=True) # always force back to cpu and np\n",
    "    all_vgg_feats.extend(result)\n",
    "all_vgg_feats = np.array(all_vgg_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a2cc72-4f8c-4b7f-910f-95adda960cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "subject_vgg_data = []\n",
    "for i in subject_data:\n",
    "    subject_vgg_data.append(all_vgg_feats[count:count+i.shape[0],:])\n",
    "    count += i.shape[0]\n",
    "subject_y_data = [np.array([subject_scores[i] for i in subj]) for subj in valid_sessions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ff3057-f940-42ec-afc3-fe7ca6e9304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = []\n",
    "for n_subj in range(len(subject_vgg_data)):\n",
    "    X_train_vgg = np.concatenate([subject_vgg_data[i] for i in range(len(subject_vgg_data)) if i != n_subj])\n",
    "    y_train_vgg = np.concatenate([subject_y_data[i] for i in range(len(subject_y_data)) if i != n_subj])\n",
    "    X_test_vgg = subject_vgg_data[n_subj]\n",
    "    y_test_vgg = subject_y_data[n_subj]\n",
    "\n",
    "    # transform y to binary\n",
    "    y_train = np.array(y_train_vgg >= 5, dtype=np.int8)\n",
    "    y_test = np.array(y_test_vgg >= 5, dtype=np.int8)\n",
    "    # print(np.unique(y_train, return_counts=True))\n",
    "    # print(np.unique(y_test, return_counts=True))\n",
    "    \n",
    "    pca = PCA(n_components=30)\n",
    "    pca.fit(X_train_vgg)\n",
    "    x_train = pca.transform(X_train_vgg)\n",
    "    \n",
    "    # Note: data are _roughly_ balanced, not forcing balanced so using equal priors\n",
    "    lda = LinearDiscriminantAnalysis(priors=(0.5,0.5))\n",
    "    lda.fit(x_train, y_train)\n",
    "\n",
    "    \n",
    "    x_test = pca.transform(X_test_vgg)\n",
    "    pred_score = lda.score(x_test, y_test)\n",
    "\n",
    "    test_acc.append(pred_score)\n",
    "    \n",
    "print(np.mean(test_acc), np.std(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4db742e-a46d-4edb-9855-cde05fc8134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "X_train_vgg = np.concatenate(subject_vgg_data)\n",
    "y_train_vgg = np.concatenate(subject_y_data)\n",
    "y_train = np.array(y_train_vgg >= 5, dtype=np.int8)\n",
    "\n",
    "test_acc = []\n",
    "for i in tqdm(range(len(y_train))):\n",
    "    pca = PCA(n_components=30)\n",
    "    x_train = pca.fit_transform(np.concatenate((X_train_vgg[:i,:], X_train_vgg[i+1:,:])))\n",
    "    y_train_ = np.concatenate((y_train[:i], y_train[i+1:]))\n",
    "\n",
    "    # Note: data are _roughly_ balanced, not forcing balanced so using equal priors\n",
    "    lda = LinearDiscriminantAnalysis(priors=(0.5,0.5))\n",
    "    lda.fit(x_train, y_train_)\n",
    "\n",
    "    x_test = pca.transform(np.expand_dims(X_train_vgg[i], axis=0))\n",
    "    pred_score = lda.score(x_test, [y_train[i]])\n",
    "\n",
    "    test_acc.append(pred_score)\n",
    "    \n",
    "print(np.mean(test_acc), np.std(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c869cd18-5d23-49d5-b2e5-c4ac575b467f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
